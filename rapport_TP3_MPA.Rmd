---
title: "rapport_TP3_MPA"
author: "BON, BARON, FOUSSE"
date: "11/10/2020"
output: html_document
---

#Partie 1

## Question 1

La loi générative s'exprime sous la forme :
\[
p(y|\theta) = \prod_{i=1}^{n} p(y_i|\theta) = \prod_{i=1}^n e^{-\theta} \times \frac{\theta^{y_i}}{y_i!} = e^{-n\theta} \times \frac{\theta^{\sum_{i=1}^n y_i}}{\prod_{i=1}^n y_i!} = e^{-n\theta} \times \frac{\theta^{n\overline{y}}}{\prod_{i=1}^ny_i!}
\]

##Question 2

Pour déterminer la loi a posteriori, on utilise la formule de Bayes :

\[
p(\theta|y) \propto p(\theta)p(y|\theta) \propto \frac{1}{\theta}e^{-n\theta}\frac{\theta^{n\overline{y}}}{\prod_{i=1}^ny_i!} \propto e^{-n\theta} \theta^{n\overline{y} - 1}
\]
avec $\overline{y} la moyenne empirique des données.

On peut calculer la constante de normalisation $C$ en intégrant cette expression par rapport à $\theta$.

\[
C = \int_0^{+\infty}e^{-n\theta}\theta^{n\overline{y} - 1}d\theta
\]
En effectuant $n\overline{y}-1$ intégrations par parties, on arrive à :
\[
C = \frac{(n\overline{y} - 1)!}{n^{n\overline{y} - 1}}
\]

Ainsi, finalement on obtient :
\[
p(\theta|y) = \frac{1}{C}e^{-n\theta}\theta^{n\overline{y} - 1}
\]

On peut à présent calculer l'espérance de la loi a posteriori :

\[
\mathbb{E}(\theta|y) = \frac{1}{C}\int_0^{+\infty}\theta p(\theta|y)d\theta = \frac{1}{C}\int_0^{+\infty}e^{-n\theta}\theta^{n\overline{y}}d\theta
\]

En réutilisant le calcul de la constante, on aboutit à :

\[
\mathbb{E}(\theta|y) = \frac{1}{C}\frac{(n\overline{y})!}{n^{n\overline{y} + 1}} = \frac{n\overline{y}}{n} = \overline{y}
\]




```{R}
theta = 11
n = 30
y = rpois(n, theta)

# y_read = scan(file = 'TP3_mpa_2020.txt')
# y = c()
# for (i in seq(1:40)){
#   y = c(y, y_read[i])
# }




les_thetas = c()
for (i in seq(1:1000)){
  #Metropolis-Hastings
  
  #Etape 1
  niter = 1000
  t = 0
  theta.t = 11

  for (k in seq(1:niter)){
    #Etape 2
    theta.star = rexp(1, rate=1/theta.t)
    #Etape 3
    if ((theta.star / theta.t)^(n*mean(y) - 1) != Inf){
      r = exp(-n * (theta.star - theta.t)) * (theta.star / theta.t)^(n*mean(y) - 1) * dexp(theta.t, rate=1/theta.star) / dexp(theta.star, rate=1/theta.t)
     # print(r)
      if (is.nan(r)){
        next
      }
        #etape 4
      if (1 < r){
        p = 1
      }
      else{
        p = r
      }
    }
    else{
      p = 1
      
    }
    tirage = runif(1)
    if (tirage < p){
      theta.t = theta.star
    }
    #etape 5 done
  }
  les_thetas = c(les_thetas, theta.t)
}



print(length(les_thetas) - length(les_thetas_filtres))
hist(les_thetas, breaks=50, prob=T, main=NULL, xlim=c(0, 30), ylim = c(0,1), col="red")  #histogramme normalisé à 1
x_graph = seq(from=0, to=20, by=0.1)
y_graph = dgamma(x_graph, shape=n*mean(y), scale=1/n)
lines(x_graph, y_graph)

```
L'histogramme correspond. Il serait probablement plus performant avec plus de données, mais cela donnerait des valeurs trop grandes pour êtres calculées par R
